{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQEeydtPujvMlZXN/ng38z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KartikayBhardwaj-dev/COLLEGE/blob/main/week8_graded_1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "4F1FVGSpGuva"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/processed_data.csv')"
      ],
      "metadata": {
        "id": "SoDqVUCnHJEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-hin1GCHRts",
        "outputId": "3bb84ad8-1b95-4930-befa-7a06dacff6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16363 entries, 0 to 16362\n",
            "Data columns (total 8 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   text              16363 non-null  object \n",
            " 1   sentiment         16363 non-null  object \n",
            " 2   Time of Tweet     16363 non-null  object \n",
            " 3   Age of User       16363 non-null  object \n",
            " 4   Land Area (Km²)   16363 non-null  float64\n",
            " 5   Continent         14416 non-null  object \n",
            " 6   Density_Level     16363 non-null  object \n",
            " 7   Population_Group  16363 non-null  object \n",
            "dtypes: float64(1), object(7)\n",
            "memory usage: 1022.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QFSfJuWbHotk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_df , X_test_df = train_test_split(df,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "Lm6BzAN_HavX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_text = \" \".join(X_train['text']).lower()\n",
        "words = re.findall(r'\\b\\w+\\b', all_text)\n",
        "unique_words = set(words)\n",
        "print(len(unique_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o056pU7TIYpV",
        "outputId": "00fb4066-9257-4439-8d19-212781df6dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['text'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFWk1CrCH2uk",
        "outputId": "0d1529b6-cd7b-459e-9c1a-66098de8e339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' come home, then. Not so boring here.',\n",
              "       'Is feeling like he has a bad flu. Yes. Bad. Flu.',\n",
              "       ' have a lok at EF too! they are jummy', ...,\n",
              "       'Happy Mothers Day! Will be going out later at 6 pm to watch a well renowned group of singers!',\n",
              "       'ummm sooo yeh....its really hard to concentrate rite now wen i have this weird #lupus feeling goin thro my body',\n",
              "       'Good morning Tweeple of the sun! What you all up to?'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESSING\n",
        "- Apply preprocessing to the features of both the training and test datasets as follows:\n",
        "\n",
        "- For numerical Feature (Land Area (Km²))\n",
        "  * scale using StandardScaler.\n",
        "\n",
        "- For ordinal feautres (Density_Level, Population_Group)\n",
        "  * Apply OrdinalEncoder with the following category mapping: \"Low\" → 0, \"Medium\" → 1, \"High\" → 2.\n",
        "\n",
        "- For nominal features (Age of User, Time of Tweet, Continent)\n",
        "  * Use OneHotEncoder with sparse_ouput=False and drop=first\n",
        "\n",
        "- For text features (text)\n",
        "  * Apply TfidfVectorizer with the following parameters:\n",
        "\n",
        "    * lowercase=True\n",
        "    * stop_words=english\n",
        "    * max_features=5000\n",
        "    * ngram_range=(1, 2)\n",
        "    * token_pattern=r(?u)\\b\\w\\w+\\b|[@#]\\w+ (to include hashtags and mentions)\n",
        "    * strip_accents=unicode (to normalize characters like \"é\")"
      ],
      "metadata": {
        "id": "iqBy03Y4Kp0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ct = ColumnTransformer([\n",
        "    ('numerical' , StandardScaler() , ['Land Area (Km²)']),\n",
        "    ('ordinal' , OrdinalEncoder(categories=[[\"Low\",\"Medium\",\"High\"],[\"Low\", \"Medium\", \"High\"]]),['Density_Level', 'Population_Group']),\n",
        "    ('nominal' , OneHotEncoder(sparse_output=False,drop='first'),['Age of User','Time of Tweet','Continent']),\n",
        "    ('text' , TfidfVectorizer(\n",
        "        lowercase=True,\n",
        "        stop_words='english',\n",
        "        max_features=5000,\n",
        "        ngram_range=(1, 2),\n",
        "        token_pattern=r'(?u)\\b\\w\\w+\\b|[@#]\\w+',\n",
        "        strip_accents='unicode'\n",
        "    ),'text')\n",
        "])"
      ],
      "metadata": {
        "id": "YgrZPT1YI0V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train= ct.fit_transform(X_train_df)\n",
        "X_test =ct.transform(X_test_df)"
      ],
      "metadata": {
        "id": "be4QDijqOYfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[:5].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH9mEeZOPFqa",
        "outputId": "d025a74c-b37d-4642-b60c-e6a57d47ad8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(26.885773869406624)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xMK5XB7JQWge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL BUILDING"
      ],
      "metadata": {
        "id": "naCisb_uQANT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine features (excluding 'Land Area (Km²)')\n",
        "ord_features = ['Density_Level', 'Population_Group']\n",
        "nom_features = ['Age of User', 'Time of Tweet', 'Continent']\n",
        "text_feature = 'text'\n",
        "\n",
        "# Ordinal encoding order\n",
        "ordinal_mapping = [['Low', 'Medium', 'High'], ['Low', 'Medium', 'High']]\n",
        "\n",
        "# Define transformers\n",
        "ord_transformer = OrdinalEncoder(categories=ordinal_mapping)\n",
        "nom_transformer = OneHotEncoder(sparse_output=False, drop='first')\n",
        "text_transformer = TfidfVectorizer(\n",
        "    lowercase=True,\n",
        "    stop_words='english',\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 2),\n",
        "    token_pattern=r'(?u)\\b\\w\\w+\\b|[@#]\\w+',\n",
        "    strip_accents='unicode'\n",
        ")\n",
        "\n",
        "# ColumnTransformer excluding the numerical feature\n",
        "preprocessor_nb = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('ord', ord_transformer, ord_features),\n",
        "        ('nom', nom_transformer, nom_features),\n",
        "        ('text', text_transformer, text_feature)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Transform data\n",
        "X_train_nb = preprocessor_nb.fit_transform(X_train_df)\n",
        "X_test_nb = preprocessor_nb.transform(X_test_df)\n",
        "y_train = X_train_df['sentiment']\n",
        "y_test = X_test_df['sentiment']\n",
        "\n",
        "# Train the MultinomialNB model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train_nb, y_train)\n",
        "\n",
        "# Predict and calculate log loss\n",
        "y_proba = model.predict_proba(X_test_nb)\n",
        "loss = log_loss(y_test, y_proba)\n",
        "\n",
        "# Output the result\n",
        "print(\"Log Loss:\", round(loss, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJSYNfkEUnpg",
        "outputId": "ed468e53-fbb4-4d50-edea-898150dc46b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Loss: 0.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ERROR ANALYSIS\n",
        "- Train a RandomForestClassifier with random_state=42 on the preprocessed training dataset. This time, include all features, including Land Area (Km²), in both the training and test datasets."
      ],
      "metadata": {
        "id": "z4iuMkAzVCMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine features (excluding 'Land Area (Km²)')\n",
        "num_feature = ['Land Area (Km²)']\n",
        "ord_features = ['Density_Level', 'Population_Group']\n",
        "nom_features = ['Age of User', 'Time of Tweet', 'Continent']\n",
        "text_feature = 'text'\n",
        "\n",
        "# Ordinal encoding order\n",
        "ordinal_mapping = [['Low', 'Medium', 'High'], ['Low', 'Medium', 'High']]\n",
        "\n",
        "# Define transformers\n",
        "num_transformer = StandardScaler()\n",
        "ord_transformer = OrdinalEncoder(categories=ordinal_mapping)\n",
        "nom_transformer = OneHotEncoder(sparse_output=False, drop='first')\n",
        "text_transformer = TfidfVectorizer(\n",
        "    lowercase=True,\n",
        "    stop_words='english',\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 2),\n",
        "    token_pattern=r'(?u)\\b\\w\\w+\\b|[@#]\\w+',\n",
        "    strip_accents='unicode'\n",
        ")\n",
        "\n",
        "# ColumnTransformer excluding the numerical feature\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', num_transformer, num_feature),\n",
        "        ('ord', ord_transformer, ord_features),\n",
        "        ('nom', nom_transformer, nom_features),\n",
        "        ('text', text_transformer, text_feature)\n",
        "    ]\n",
        ")\n",
        "X_train = preprocessor.fit_transform(X_train_df)\n",
        "X_test = preprocessor.transform(X_test_df)\n",
        "y_train = X_train_df['sentiment']\n",
        "y_test = X_test_df['sentiment']"
      ],
      "metadata": {
        "id": "X9R3kuw5Vouq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RandomForestClassifier(random_state=42)\n",
        "model2.fit(X_train,y_train)\n",
        "y_pred = model2.predict(X_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred, labels=['positive', 'negative'])\n",
        "conf_df = pd.DataFrame(conf_matrix, index=['Actual_Pos', 'Actual_Neg'], columns=['Pred_Pos', 'Pred_Neg'])\n",
        "\n",
        "# Display confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_df)\n"
      ],
      "metadata": {
        "id": "wgMhB09FVJLR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1753ac64-30bd-4c32-e163-44ce32b71a94"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "            Pred_Pos  Pred_Neg\n",
            "Actual_Pos      1474       267\n",
            "Actual_Neg       184      1348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KZLW7dTXXUBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = LogisticRegression(random_state=42,max_iter=1000)\n",
        "selector = RFECV(estimator=estimator,step=100,n_jobs=-1,cv=5)\n",
        "selector.fit(X_train,y_train)\n",
        "selected_features = selector.support_.sum()"
      ],
      "metadata": {
        "id": "G_f3AC2xWmiI"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-tOIc3WX7u-",
        "outputId": "08f52bf9-89cb-4781-c015-d1a82d2d55db"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(4216)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    }
  ]
}